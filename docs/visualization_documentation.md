# Visualization Module Documentation

This document provides a detailed explanation of the visualization module located in the `src/visualization/` directory. The module implements tools for visualizing audio data, particularly impulse responses and frequency spectra.

## Table of Contents

1. [Overview](#overview)
2. [File Structure](#file-structure)
3. [WaveformRenderer Class (`waveform-renderer.ts`)](#waveformrenderer-class-waveform-rendererts)
4. [FFT Class (Internal to WaveformRenderer)](#fft-class-internal-to-waveformrenderer)
5. [Key Visualization Techniques](#key-visualization-techniques)
6. [Relationships with Other Modules](#relationships-with-other-modules)

## Overview

The visualization module provides graphical representations of audio data generated by the spatial audio simulation. It renders waveforms and spectrograms to help users understand the acoustic properties of the simulated environment. The visualizations display both time-domain (waveform) and frequency-domain (spectrogram) representations of impulse responses.

The system provides:
- Stereo waveform visualization with separate left and right channels
- Time-frequency spectrogram using FFT analysis
- Interactive display with proper time and frequency labeling
- Real-time updates when the acoustic simulation changes

## File Structure

The visualization module consists of the following file:

- `waveform-renderer.ts`: Implements the WaveformRenderer class for drawing waveforms and spectrograms

## WaveformRenderer Class (`waveform-renderer.ts`)

### Purpose
Renders audio data as visual waveforms and spectrograms on HTML canvas elements, providing both time-domain and frequency-domain representations of impulse responses.

### Key Components

#### Properties
- `canvas`: Main HTML canvas element for waveform display
- `ctx`: 2D rendering context for the main canvas
- `fftCanvas`: Secondary HTML canvas element for spectrogram display
- `fftCtx`: 2D rendering context for the FFT canvas
- `analyser`: Web Audio API AnalyserNode for audio analysis
- `audioCtx`: Web Audio API AudioContext for audio processing

#### Important Methods

- **Constructor**: Sets up the canvas elements and initializes Web Audio API components
  ```typescript
  constructor(canvas: HTMLCanvasElement)
  ```
  This method:
  1. Stores the provided canvas and gets its 2D context
  2. Creates a secondary canvas for the spectrogram
  3. Initializes Web Audio API components
  4. Sets up event listeners for window resizing

- **drawWaveform**: Renders a stereo waveform visualization
  ```typescript
  public drawWaveform(stereoData: Float32Array): void
  ```
  This method:
  1. Splits the stereo data into left and right channels
  2. Calculates the maximum amplitude for proper scaling
  3. Draws a grid and zero line for reference
  4. Renders the left channel in green in the upper half
  5. Renders the right channel in blue in the lower half
  6. Adds time markers along the bottom

- **drawWaveformWithFFT**: Renders both waveform and spectrogram visualizations
  ```typescript
  public async drawWaveformWithFFT(stereoData: Float32Array): Promise<void>
  ```
  This method:
  1. Calls `drawWaveform` to render the time-domain representation
  2. Extracts the left channel for FFT analysis
  3. Performs Short-Time Fourier Transform (STFT) analysis
  4. Generates a spectrogram image with color-coded frequency content
  5. Adds frequency and time axis labels

- **resize**: Handles canvas resizing to maintain proper display
  ```typescript
  private resize(): void
  ```
  Adjusts canvas dimensions to match their display size when the window is resized.

### Visualization Techniques

#### Waveform Visualization
- Displays stereo audio with left and right channels separated
- Uses smooth quadratic curves for better visual appearance
- Implements proper scaling to handle varying amplitude ranges
- Includes grid lines and time markers for reference

#### Spectrogram Visualization
- Uses Short-Time Fourier Transform (STFT) for time-frequency analysis
- Implements logarithmic frequency scaling for better perceptual representation
- Uses color gradients to represent energy levels across frequencies
- Includes labeled frequency and time axes

## FFT Class (Internal to WaveformRenderer)

### Purpose
Implements the Fast Fourier Transform algorithm to convert time-domain audio data to frequency-domain representations for spectrogram visualization.

### Key Components

#### Properties
- `size`: Size of the FFT (must be a power of 2)
- `real`: Float32Array for real components
- `imag`: Float32Array for imaginary components
- `cosTable` and `sinTable`: Precomputed trigonometric values for efficiency

#### Important Methods

- **Constructor**: Initializes the FFT processor with the specified size
  ```typescript
  constructor(size: number)
  ```
  Precomputes trigonometric tables for efficient FFT calculation.

- **transform**: Performs the FFT on the input data
  ```typescript
  transform(input: Float32Array): { magnitudes: Float32Array, phases: Float32Array }
  ```
  This method:
  1. Copies input data to the real array and clears the imaginary array
  2. Performs bit-reversal permutation
  3. Implements the Cooley-Tukey FFT algorithm
  4. Calculates magnitude and phase for each frequency bin
  5. Returns the frequency-domain representation

- **reverseBits**: Helper method for the FFT algorithm
  ```typescript
  private reverseBits(x: number, n: number): number
  ```
  Performs bit reversal required by the FFT algorithm.

## Key Visualization Techniques

### Waveform Rendering
The waveform visualization provides a time-domain representation of the impulse response:
1. **Channel Separation**: Left and right channels are displayed separately for stereo analysis
2. **Amplitude Scaling**: Dynamic scaling ensures optimal visibility regardless of signal level
3. **Smooth Rendering**: Quadratic curves create a smoother, more visually appealing waveform
4. **Time Reference**: Grid lines and time markers help interpret the temporal characteristics

### Spectrogram Generation
The spectrogram visualization provides a frequency-domain representation over time:
1. **Short-Time Fourier Transform**: Divides the signal into overlapping windows for time-frequency analysis
2. **Logarithmic Frequency Scaling**: Maps frequencies logarithmically to match human perception
3. **Color Mapping**: Uses color gradients to represent energy levels across the spectrum
4. **Windowing**: Applies Hann window to reduce spectral leakage
5. **Interpolation**: Implements both time and frequency interpolation for smoother visualization

### Interactive Elements
Both visualizations include interactive elements:
1. **Responsive Design**: Canvases resize with the window to maintain proper display
2. **Labeled Axes**: Time and frequency axes are labeled for easier interpretation
3. **Visual Hierarchy**: Grid lines and reference markers help interpret the data

## Relationships with Other Modules

The visualization module interacts with several other components:

- **Sound Module**: Receives audio data for visualization
  - The `AudioProcessor` class calls `visualizeImpulseResponse` to display the generated impulse response
  - Processes stereo impulse response data from the audio processing pipeline

- **Main Application**: Initializes and manages the visualization components
  - Creates the canvas elements for visualization
  - Connects the audio processor to the visualization system
  - Triggers visualization updates when the acoustic simulation changes

- **Raytracer Module**: Indirectly provides data for visualization
  - Ray tracing results are processed by the audio module and then visualized
  - Changes in ray paths and reflections are reflected in the visualized impulse response

- **Web Audio API**: Used for audio analysis and processing
  - Leverages AnalyserNode for frequency analysis
  - Provides the foundation for audio processing and visualization
